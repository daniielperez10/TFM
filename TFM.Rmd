---
title: "TFM"
author: "DANIEL PÉREZ"
date: "2024-04-05"
output: html_document
---


```{r}
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
```

DATOS CENTRO DE MADRID
```{r}
# Inicializar una lista para almacenar los datos de todos los archivos
datos_lista <- list()

# Loop para leer cada archivo y almacenar los datos en la lista
for (year in 2017:2023) {
  # Generar el nombre del archivo para el año actual
  file_name <- paste0(year, ".csv")
  
  # Leer el archivo CSV con read_delim
  datos <- read_delim(file_name, delim = ";", escape_double = FALSE, trim_ws = TRUE)
  
  # Almacenar los datos en la lista
  datos_lista[[year - 2015]] <- datos
}



```

```{r}
df_final <- do.call(rbind, datos_lista)
```


```{r}
daily_pollution <- df_final %>% 
    rename(town_code = MUNICIPIO,
           station_code = ESTACION,
           magnitude = MAGNITUD,
           year = ANO,
           month = MES,
           provincia = PROVINCIA,
           punto_muestreo = PUNTO_MUESTREO) %>% 
    select(-matches("^V"))

daily_pollution <- daily_pollution %>%
  filter(magnitude == "8") %>% 
    select(-magnitude)
```


```{r}
daily_pollution <- daily_pollution %>%
  pivot_longer(cols = starts_with("D"),
               names_to = "dia",
               values_to = "air_quality")
```


```{r}
# Copia del dataframe para evitar modificar el original
daily_pollution_center <- daily_pollution

# Eliminar la "D" de cada observación en la columna "dia" si está presente
for (i in 1:nrow(daily_pollution_center)) {
  if (substr(daily_pollution_center$dia[i], 1, 1) == "D") {
    daily_pollution_center$dia[i] <- substr(daily_pollution_center$dia[i], 2, nchar(daily_pollution_center$dia[i]))
  }
}
```

```{r}
fecha_str <- paste(daily_pollution_center$year, daily_pollution_center$month, daily_pollution_center$dia, sep = "-")

# Convertir la cadena de fecha a un objeto de fecha
daily_pollution_center$fecha <- as.Date(fecha_str, format = "%Y-%m-%d")

```


DATOS DE LA COMUNIDAD DE MADRID, ES DECIR, NO SOLO CENTRO DE LA CIUDAD


```{r}
datos_lista_OUT <- list()

# Loop para leer cada archivo y almacenar los datos en la lista
for (year in 2017:2023) {  # Cambiado para incluir el año 2016
  # Generar el nombre del archivo para el año actual
  file_name <- paste0(year, "_out.csv")  # Cambiado para reflejar el nuevo formato del nombre del archivo
  
  # Leer el archivo CSV con read_delim
  datos_OUT <- read_delim(file_name, delim = ";", escape_double = FALSE, trim_ws = TRUE)
  
  # Almacenar los datos en la lista
  datos_lista_OUT[[year - 2015]] <- datos_OUT
}
```

```{r}
df_final_out <- do.call(rbind, datos_lista_OUT)
```



```{r}
daily_pollution_out <- df_final_out %>% 
    rename(town_code = municipio,
           station_code = estacion,
           magnitude = magnitud,
           year = ano,
           month = mes
          ) %>% 
    select(-matches("^V"))


daily_pollution_out <- daily_pollution_out %>%
  filter(magnitude == "8") %>% 
    select(-magnitude)


str(daily_pollution_out)
  

```


```{r}
# Convertir las horas de caracteres a numéricos

daily_pollution_out <- mutate(daily_pollution_out,
                               h01 = as.numeric(gsub(",", ".", h01)),
                               h02 = as.numeric(gsub(",", ".", h02)),
                               h03 = as.numeric(gsub(",", ".", h03)),
                               h04 = as.numeric(gsub(",", ".", h04)),
                               h05 = as.numeric(gsub(",", ".", h05)),
                               h06 = as.numeric(gsub(",", ".", h06)),
                               h07 = as.numeric(gsub(",", ".", h07)),
                               h08 = as.numeric(gsub(",", ".", h08)),
                               h09 = as.numeric(gsub(",", ".", h09)),
                               h10 = as.numeric(gsub(",", ".", h10)),
                               h11 = as.numeric(gsub(",", ".", h11)),
                               h12 = as.numeric(gsub(",", ".", h12)),
                               h13 = as.numeric(gsub(",", ".", h13)),
                               h14 = as.numeric(gsub(",", ".", h14)),
                               h15 = as.numeric(gsub(",", ".", h15)),
                               h16 = as.numeric(gsub(",", ".", h16)),
                               h17 = as.numeric(gsub(",", ".", h17)),
                               h18 = as.numeric(gsub(",", ".", h18)),
                               h19 = as.numeric(gsub(",", ".", h19)),
                               h20 = as.numeric(gsub(",", ".", h20)),
                               h21 = as.numeric(gsub(",", ".", h21)),
                               h22 = as.numeric(gsub(",", ".", h22)),
                               h23 = as.numeric(gsub(",", ".", h23)),
                               h24 = as.numeric(gsub(",", ".", h24)))


# Calcular la media diaria

daily_pollution_out <- mutate(daily_pollution_out,
                               air_quality = rowMeans(select(daily_pollution_out, starts_with("h")), na.rm = TRUE)) 

daily_pollution_out <- mutate(daily_pollution_out,
                               air_quality = round(air_quality))


daily_pollution_out <- daily_pollution_out %>%
                         select(-starts_with("h"))

```




```{r}
fecha_str <- paste(daily_pollution_out$year, daily_pollution_out$month, daily_pollution_out$dia, sep = "-")

# Convertir la cadena de fecha a un objeto de fecha
daily_pollution_out$fecha <- as.Date(fecha_str, format = "%Y-%m-%d")
```

```{r}
daily_pollution_center$city_center <- 1
daily_pollution_out$city_center <- 0
```

```{r}
df_pollution <- rbind(daily_pollution_center, daily_pollution_out)
unique_values2 <- unique(df_pollution$punto_muestreo)
print(unique_values2)
```

```{r}
# Crea una variable dummy que tome el valor 1 para fechas a partir del 30 de noviembre de 2018 (fecha de entrada en vigor de Madrid Central)
df_pollution$post_treat_mad_central<- ifelse(df_pollution$fecha >= as.Date("2018-11-30"), 1, 0)

df_pollution$post_treat_mad_central <- as.integer(df_pollution$post_treat_mad_central)
```


```{r}
df_pollution$post_treat_mad_360<- ifelse(df_pollution$fecha >= as.Date("2021-12-11"), 1, 0)

df_pollution$post_treat_mad_360<- as.integer(df_pollution$post_treat_mad_360)
```

```{r}

df_pollution$air_quality <- as.numeric(df_pollution$air_quality)

#eliminar Na´s de fecha ya que los datos tienen 31 días por defecto incluso para aquellos meses en los que no hay 31 días.
df_pollution <- df_pollution[!is.na(df_pollution$fecha), ]

df_pollution <- df_pollution |> 
  mutate(punto_muestreo = str_replace(punto_muestreo, "_[^_]+_[^_]+$", ""))

str(df_pollution)

#write.csv(df_pollution, file = "df_pollution.csv", row.names = FALSE)

```

INFORMACIÓN DE ESTACIONES CENTRO CIUDAD

```{r}
city_stations <- read_delim("informacion_estaciones_red_calidad_aire.csv", delim=";")

city_stations <- city_stations |> 
   select(
     punto_muestreo = CODIGO,
     station_code = CODIGO_CORTO,
     station_name = ESTACION,
     address = DIRECCION,
     station_type = NOM_TIPO,
     longitude = LONGITUD,
     latitude = LATITUD) %>% 
    mutate(station_code = as.character(station_code))


city_stations <- city_stations %>%
  mutate(
    station_type = str_replace_all(station_type, "tráfico", "trafico"),
    station_type = str_to_title(station_type),
    station_type = str_replace_all(station_type, "\\bfondo\\b", "Fondo"),
    station_type = str_replace_all(station_type, "\\bindustrial\\b", "Industrial"),
    station_type = str_replace_all(station_type, "\\btrafico\\b", "Trafico")
  )


   
```

INFORMACIÓN ESTACIONES FUERA DEL CENTRO DE MADRID

```{r}
com_stations <- read_delim("com_stations.csv", delim=";")

library(dplyr)
library(stringr)


com_stations <- com_stations |> 
  mutate(
    punto_muestreo = estacion_codigo,
    station_code = str_sub(estacion_codigo, -2, -1),
    station_code = if_else(str_starts(station_code, "0"),
                           str_remove(station_code, "^0"),
                           station_code))


  com_stations <- com_stations |> 
  select(station_name = estacion_municipio,
          punto_muestreo,
          station_code,
          station_type = estacion_tipo_estacion,
          area_type = estacion_tipo_area,
          address = estacion_direccion_postal,
          longitude = estacion_coord_longitud,
          latitude = estacion_coord_latitud) 
  
com_stations <- com_stations %>%
  mutate(station_type = paste(area_type, station_type, sep = " ")) |> 
  select(-area_type)


# Fix the latitude and longitude columns using regular expressions
com_stations<- com_stations %>%
  # Remove quotes at the beginning and end of the longitude column
  mutate(longitude = str_remove(longitude, "^\"|\",\\s*\"$")) %>%
  # Replace commas with periods in the longitude column and convert to numeric
  mutate(longitude = as.numeric(gsub(",", ".", longitude))) %>% 
  # Remove quotes and commas from the end of the latitude column
  mutate(latitude = str_remove(latitude, "\"?,?$")) %>%
  # Replace commas with periods in the latitude column and convert to numeric
  mutate(latitude = as.numeric(gsub(",", ".", latitude))) 

# Remove any sequence of two commas AND quotation marks from the address column
com_stations <- com_stations%>% 
  # Remove quotes from the address column
  mutate(address = str_remove(address, '["\']')) %>% 
  # Remove any sequence of two commas from the address column
  mutate(address = str_remove(address, ",{2}"))
```
Comprobar punto muestreo de cada dataset

```{r}
unique_values1<- unique(daily_pollution_center$punto_muestreo)

unique_values3 <- unique(city_stations$punto_muestreo)

print(unique_values1)
print(unique_values3)

#Vemos que son los mismos 
```


```{r}
unique_values2 <- unique(daily_pollution_out$punto_muestreo)
unique_values4 <- unique(com_stations$punto_muestreo)
print(unique_values2) 
print(unique_values4)

#Vemos que en el dataframe de datos de contaminación hay más estaciones. Las que faltan se corresponden con datos de 2023 y presentan Na´s por lo que son eliminadas para tener información completa de todas las estaciones
```


```{r}
# Lista de valores a eliminar
valores_a_eliminar <- c("28134002", "28115003", "28106001", "28127004")

# Filtrar el dataframe para eliminar las observaciones con esos valores en punto_muestreo
df_pollution <- df_pollution %>%
  filter(!punto_muestreo %in% valores_a_eliminar)

# Verificar los cambios
print(df_pollution)
```
Juntar ambos dataframes con informacion sobre las estaciones

```{r}
estaciones <- bind_rows(city_stations, com_stations)
```



TEMPERATURAS


```{r}
#install.packages("climaemet")
library(climaemet)

aemet_api_key("eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIxMDA0MDc1NDNAYWx1bW5vcy51YzNtLmVzIiwianRpIjoiMTdlZWU2ZTctY2Y4Yi00N2EzLWE5ZDctYjU1YThmM2Y4OWIyIiwiaXNzIjoiQUVNRVQiLCJpYXQiOjE3MTMwMjM5MjYsInVzZXJJZCI6IjE3ZWVlNmU3LWNmOGItNDdhMy1hOWQ3LWI1NWE4ZjNmODliMiIsInJvbGUiOiIifQ.J2RUdWytG5Y1ZPeHxFZ8pzPeu-QzhHRvHAcOochG0N0", overwrite = TRUE, install = TRUE)
```


```{r}


#weather_full_2 <- aemet_daily_clim(station = "all", start = "2015-01-01", end = "2023-12-31",                                 verbose = FALSE, return_sf = FALSE) |>  filter(provincia == "MADRID") 

df_weather_full_2 <- read_csv("df_weather_full_2.csv")


#write.csv(weather_full_2, file = "df_weather_full_2.csv", row.names = FALSE)
```


```{r}
weather_stations <- aemet_stations(verbose = FALSE, return_sf = FALSE) %>% 
  filter(provincia == "MADRID") %>% 
  select(-c(indicativo, indsinop, provincia)) %>% 
  rename(altitude = altitud,
         longitude = longitud,
         latitude = latitud)

```

```{r}
weather_data <- inner_join(df_weather_full_2, weather_stations, by = "nombre")
```



```{r}
library(geosphere)
library(dplyr)

# Crear una matriz de coordenadas para las estaciones de contaminación del aire
coords_pollution <- as.matrix(estaciones[, c("longitude", "latitude")])

# Crear una matriz de coordenadas para las estaciones meteorológicas
coords_weather <- as.matrix(weather_data[, c("longitude", "latitude")])

# Calcular distancias entre cada estación de contaminación del aire y cada estación meteorológica
distances <- distm(coords_pollution, coords_weather, fun = distHaversine)

# Encontrar el índice de la estación meteorológica más cercana para cada estación de contaminación del aire
closest_weather_index <- apply(distances, 1, which.min)

# Asignar el nombre de la estación meteorológica más cercana a cada estación de contaminación del aire
estaciones$nombre_meteorologica <- weather_data$nombre[closest_weather_index]

# Verificar las primeras filas del resultado
head(estaciones)


```


```{r}
str(estaciones)
str(df_pollution)

estaciones <- estaciones %>%
  mutate(punto_muestreo = as.character(punto_muestreo))

df_combined <- df_pollution %>%
  left_join(estaciones, by = "punto_muestreo")

#write.csv(df_combined, file = "df_combined.csv", row.names = FALSE)

```

```{r}
weather_data$nombre_meteorologica <- weather_data$nombre
weather_data <- weather_data |> 
  filter(fecha >= as.Date("2017-01-01"))

weather_data <- weather_data |>
  select(c(1, 5:8, 10, 12:14, 16, 18, 20, 21, 23, 25, 29)) |>
  mutate(
    prec = as.numeric(gsub(",", ".", prec)),
    dir = as.numeric(dir),
  )

weather_data <- weather_data |> 
  select(c(1:11, 15:16))
```


```{r}
library(mice)
m=10
predictor_matrix <- matrix(0, nrow = ncol(weather_data), ncol = ncol(weather_data))
rownames(predictor_matrix) <- colnames(weather_data)
colnames(predictor_matrix) <- colnames(weather_data)

# Especificamos qué variables se utilizarán como predictores para cada variable con valores faltantes
predictor_matrix['tmin', c('fecha', 'tmin')] <- 1
predictor_matrix['tmed', c('fecha', 'tmax', 'tmin')] <- 1
predictor_matrix['tmax', c('fecha', 'tmax', 'tmin')] <- 1
predictor_matrix['dir', c('fecha', 'altitud', 'dir')] <- 1

mice_mod <- mice(weather_data, m=10, predictorMatrix = predictor_matrix)
datos1 <- complete(mice_mod, action=m)


colSums(is.na(datos1))


```


```{r}
df_combined <- df_combined %>%
  mutate(
    nombre_meteorologica = as.character(nombre_meteorologica),
    fecha = as.Date(fecha)
  )


str(df_combined)

# Convertir las columnas a caracteres y fechas en weather_data
weather_data <- datos1 %>%
  mutate(
    nombre_meteorologica = as.character(nombre_meteorologica),
    fecha = as.Date(fecha)
  )

str(weather_data)

```


```{r}

# Unir los dataframes por la columna nombre_meteorologia en df_combined y nombre en weather_data
df_combined_result <- df_combined %>%
  left_join(weather_data, by = c("nombre_meteorologica", "fecha"))


rows_with_nas <- df_combined_result %>%
  filter(rowSums(is.na(.)) > 0)


print(rows_with_nas)

```
Como se puede observar faltan datos sobre el clima para ciertos días. En este caso, imputamos los datos de temperatura, precipitaciones etc con los datos del día anterior para esa estación

```{r}
df_combined_result <- df_combined_result%>%
  arrange(nombre_meteorologica, fecha)

df_combined_imputed <- df_combined_result %>%
  group_by(nombre_meteorologica) %>%
  fill(altitud, tmed, prec, tmin, tmax, dir, velmedia, racha, presMax, presMin, sol, .direction = "down")
```

Para aquellos días que no disponemos de datos climáticos, imputamos con los valores del día anterior o el día más cercano para el que no falten datos.

```{r}
write.csv(df_combined_imputed, file = "df_combined_complete.csv", row.names = FALSE)
```


```{r}
```




#########################################################################################



```{r}
data_pre_policy <- df_combined %>% filter(fecha < as.Date('2018-11-30'))
data_pre_policy <- df_combined %>% filter(city_center == 1)

data_pre_policy <- data_pre_policy %>%
  mutate(year = as.numeric(year),
         month = as.numeric(month),
         day = as.numeric(dia))

data_pre_policy <- data_pre_policy %>% 
  select(station_code.x, year, month, day, air_quality, latitude, longitude, punto_muestreo, station_type, station_name)
```

```{r}
library(tidyverse)
library(caret)
library(randomForest)

set.seed(42)

trainIndex <- createDataPartition(data_pre_policy$air_quality, p = 0.8, list = FALSE)
train_data <- data_pre_policy[trainIndex, ]
test_data <- data_pre_policy[-trainIndex, ]

train_control <- trainControl(method = "cv", number = 10)  # 10-fold cross-validation

model <- train(air_quality ~ station_code.x + year + month + day + latitude + longitude , 
               data = train_data, 
               method = "rf", 
               trControl = train_control)

# Evaluar el modelo en el conjunto de prueba
predictions <- predict(model, newdata = test_data)
test_results <- data.frame(actual = test_data$air_quality, predicted = predictions)

# Calcular métricas de evaluación
rmse <- sqrt(mean((test_results$actual - test_results$predicted)^2))
mae <- mean(abs(test_results$actual - test_results$predicted))
r2 <- cor(test_results$actual, test_results$predicted)^2

print(paste("RMSE: ", rmse))
print(paste("MAE: ", mae))
print(paste("R-squared: ", r2))


# Paso 4: Realizar Predicciones Contrafactuales
# Filtrar datos después de la implementación de la política
data_post_policy <- df_combined %>% filter(fecha >= as.Date('2018-11-30'))

data_post_policy$predicted_air_quality <- predict(model, newdata = data_post_policy)
```


TEMPERATURAS


```{r}
#install.packages("climaemet")
library(climaemet)

aemet_api_key("eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIxMDA0MDc1NDNAYWx1bW5vcy51YzNtLmVzIiwianRpIjoiMTdlZWU2ZTctY2Y4Yi00N2EzLWE5ZDctYjU1YThmM2Y4OWIyIiwiaXNzIjoiQUVNRVQiLCJpYXQiOjE3MTMwMjM5MjYsInVzZXJJZCI6IjE3ZWVlNmU3LWNmOGItNDdhMy1hOWQ3LWI1NWE4ZjNmODliMiIsInJvbGUiOiIifQ.J2RUdWytG5Y1ZPeHxFZ8pzPeu-QzhHRvHAcOochG0N0", overwrite = TRUE, install = TRUE)
```


```{r}


#weather_full_2 <- aemet_daily_clim(station = "all", start = "2015-01-01", end = "2023-12-31",                                 verbose = FALSE, return_sf = FALSE) |>  filter(provincia == "MADRID") 

df_weather_full_2 <- read_csv("df_weather_full_2.csv")


#write.csv(weather_full_2, file = "df_weather_full_2.csv", row.names = FALSE)
```

```{r}
weather_stations <- aemet_stations(verbose = FALSE, return_sf = FALSE) %>% 
  filter(provincia == "MADRID") %>% 
  select(-c(indicativo, indsinop, provincia)) %>% 
  rename(altitude = altitud,
         longitude = longitud,
         latitude = latitud)

```

```{r}
weather_data <- inner_join(df_weather_full_2, weather_stations, by = "nombre")
```

```{r}

library(geosphere)

# Create a matrix of coordinates for air pollution stations
coords_pollution <- estaciones[, c("longitude", "latitude")]

# Create a matrix of coordinates for weather stations
coords_weather <- weather_data[, c("longitude", "latitude")]

# Calculate distances between each air pollution station and each weather station
distances <- distm(coords_weather, coords_pollution, fun = distHaversine)

closest_pollution_index <- apply(distances, 1, which.min)

# Reemplazar el nombre de la estación meteorológica con el nombre de la estación de contaminación más cercana
weather_stations$nombre <- estaciones$station_name[closest_pollution_index]
```

```{r}
# Instalar y cargar paquetes necesarios

library(Synth)

df_pollution$punto_muestreo <- as.numeric(df_pollution$punto_muestreo)
df_pollution$year <- as.numeric(df_pollution$year)
df_pollution$air_quality <- as.numeric(df_pollution$air_quality)
df_pollution$punto_muestreo_num <- as.numeric(as.factor(df_pollution$punto_muestreo))
sum(is.na(df_pollution$punto_muestreo))
```

```{r}
# Filtrar datos del pre-tratamiento y post-tratamiento
df_pre <- df_pollution[df_pollution$post_treat_mad_central == 0, ]
df_post <- df_pollution[df_pollution$post_treat_mad_central == 1, ]

# Identificadores de tratamiento y control
treatment_ids <- unique(df_pollution$punto_muestreo[df_pollution$city_center == 1])
control_ids <- unique(df_pollution$punto_muestreo[df_pollution$city_center == 0])

# Preparar los datos para el paquete Synth
dataprep.out <- dataprep(
  foo = df_pollution,
  predictors = c("air_quality", "year"), # predictores para crear el control sintético
  predictors.op = "mean",
  dependent = "air_quality",
  unit.variable = "station_code", # usar la versión numérica de punto de muestreo
  time.variable = "year", # variable de tiempo (año)
  treatment.identifier = treatment_ids[1], # un identificador de tratamiento
  controls.identifier = control_ids, # identificadores de control
  time.optimize.ssr = 2017, # años para optimización (normalmente coincide con los años de pre-tratamiento)
  unit.names.variable = "punto_muestreo",
  time.plot = 2017:2019 # años para graficar
)

# Evaluar el impacto visualmente
path.plot(dataprep.res = dataprep_out, synth.res = synth_out)

# Evaluar el impacto numéricamente
synth.tables <- synth.tab(dataprep.res = dataprep_out, synth.res = synth_out)
print(synth.tables)

# Comparar la diferencia en el período post-tratamiento
gaps <- dataprep_out$Y1 - synth_out$Y0.synth
plot(2017:2019, gaps, type = "l", xlab = "Año", ylab = "Diferencia en Calidad del Aire", main = "Impacto de Madrid Central")
abline(v = 2019, col = "red") # marcar el año del tratamiento


```

```{r}
required_columns <- c("air_quality", "year", "punto_muestreo_num", "city_center")
if (all(required_columns %in% colnames(df_pollution)) &&
    is.numeric(df_pollution$year) &&
    is.numeric(df_pollution$punto_muestreo_num) &&
    is.numeric(df_pollution$air_quality)) {
  
  dataprep_out <- dataprep(
    foo = df_pollution,
    predictors = c("air_quality"),
    predictors.op = "mean",
    time.predictors.prior = c(2017, 2018),
    dependent = "air_quality",
    unit.variable = "punto_muestreo_num",
    time.variable = "year",
    treatment.identifier = unique(df_pollution$punto_muestreo_num[df_pollution$city_center == 1])[1],
    controls.identifier = unique(df_pollution$punto_muestreo_num[df_pollution$city_center == 0]),
    time.optimize.ssr = c(2017, 2018),
    unit.names.variable = "punto_muestreo_num",
    time.plot = c(2017, 2018, 2019)
  )
  
synth_out <- synth(dataprep_out)
  
  
  # Evaluar el impacto visualmente
path.plot(dataprep.res = dataprep_out, synth.res = synth_out)

# Evaluar el impacto numéricamente
synth.tables <- synth.tab(dataprep.res = dataprep_out, synth.res = synth_out)
print(synth.tables)

# Comparar la diferencia en el período post-tratamiento
gaps <- dataprep_out$Y1 - synth_out$Y0.synth
plot(2017:2019, gaps, type = "l", xlab = "Año", ylab = "Diferencia en Calidad del Aire", main = "Impacto de Madrid Central")
abline(v = 2019, col = "red") # marcar el año del tratamiento

```



```{r}
#devtools::install_github("synth-inference/synthdid")
library(synthdid)
```

```{r}
filtered_stations <- subset(df_pollution, city_center == 1)

# Extraer los códigos de estación de las filas filtradas
stations_treated <- unique(filtered_stations$station_code)

# Instala y carga las librerías necesarias
install.packages("Synth", dependencies = TRUE)
library(Synth)
# Cargar la biblioteca synth
library(synth)

# Suponiendo que ya has leído tus datos en un dataframe llamado df_pollution

# Preparar los datos usando dataprep
dataprep_out <- dataprep(
  foo = df_pollution,
  predictors = c("year"),  # Variables predictoras
  predictors.op = "mean",  # Operador para los predictores
  dependent = "air_quality",  # Variable dependiente
  unit.variable = "station_code",  # Columna que identifica las unidades
  time.variable = "year",  # Columna que identifica los periodos de tiempo
  treatment.identifier = "stations_treated" ,  # Identificador de la unidad tratada
  controls.identifier = NULL,  # Identificador de las unidades de control
  time.predictors.prior = 2016:2017,  # Períodos previos al tratamiento para los predictores
  time.optimize.ssr = 2017:2019  # Períodos sobre los que minimizar la MSPE
)

dataprep_out <- dataprep(
  foo = df_pollution,
  predictors = c("year"),  # Variables predictoras
  predictors.op = "mean",  # Operador para los predictores
  dependent = "air_quality",  # Variable dependiente
  unit.variable = "station_code",  # Columna que identifica las unidades
  time.variable = "year",  # Columna que identifica los periodos de tiempo
  treatment.identifier = 1,  # Identificador de la unidad tratada (por ejemplo, el primer código de estación)
  controls.identifier = NULL,  # Identificador de las unidades de control
  time.predictors.prior = 2016:2017,  # Períodos previos al tratamiento para los predictores
  time.optimize.ssr = 2017:2019  # Períodos sobre los que minimizar la MSPE
)

dataprep.out <- dataprep(
  foo = df_pollution,
  predictors = c("year"),  # Variables predictoras
  predictors.op = "mean",  # Operador para los predictores
  dependent = "air_quality",  # Variable dependiente
  unit.variable = 3,  # Columna que identifica las unidades (asumiendo que station_code es la tercera columna)
  time.variable = "year",  # Columna que identifica los periodos de tiempo
  treatment.identifier = 1,  # Identificador de la unidad tratada (por ejemplo, el primer código de estación)
  controls.identifier = NULL,  # Identificador de las unidades de control
  time.predictors.prior = 2016:2017,  # Períodos previos al tratamiento para los predictores
  time.optimize.ssr = 2017:2019  # Períodos sobre los que minimizar la MSPE
)

# Aplicar el método de grupo de control sintético
synth_control <- synth(dataprep_out)

# Ver los resultados
summary(synth_control)




ENTRENAR MODELO CON DATOS PRE-TREATMENT
```


```{r}
data_pre_policy <- df_combined %>% filter(fecha < as.Date('2018-11-30'))
data_pre_policy <- df_combined %>% filter(city_center == 1)

data_pre_policy <- data_pre_policy %>%
  mutate(year = as.numeric(year),
         month = as.numeric(month),
         day = as.numeric(dia))

data_pre_policy <- data_pre_policy %>% 
  select(station_code.x, year, month, day, air_quality, latitude, longitude, punto_muestreo, station_type, station_name)
```


```{r}
```{r}
x <- data(synth.data)
str(x)
View(synth.data)
```

Suposición 4 (estabilidad de la función contrafactual):

Propósito: Asegurar que la predicción de lo que habría ocurrido sin el tratamiento es consistente y estable a lo largo del tiempo.
Analogía con Pre-tendencias: En DiD, las tendencias paralelas implican que cualquier diferencia entre los grupos después del tratamiento se debe al tratamiento. Similarmente, la estabilidad de la función contrafactual implica que cualquier diferencia observada se puede atribuir al tratamiento y no a cambios en la función de predicción.


LITERATURE REVIEW:

Chang, N. C. (2020). Double/debiased machine learning for difference-in-differences models. The Econometrics Journal, 23(2), 177-191.

https://academic.oup.com/ectj/article/23/2/177/5722119?login=false


McConnell, K. J., & Lindner, S. (2019). Estimating treatment effects with machine learning. Health services research, 54(6), 1273-1282.